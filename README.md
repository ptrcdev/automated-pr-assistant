# Automated Code Review Assistant - NestJS API

This NestJS API acts as the backend gateway for the Automated Code Review Assistant project. It receives Git webhook events, performs static code analysis using ESLint (or similar tools), and forwards code snippets to a Python AI feedback service (via a REST API) for detailed, contextual review feedback. The API then aggregates these results and returns a unified report.

---

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Technologies](#technologies)
- [Architecture](#architecture)
- [Setup and Installation](#setup-and-installation)
- [Usage](#usage)
- [Deployment](#deployment)
- [Future Improvements](#future-improvements)
- [License](#license)

---

## Overview

The Automated Code Review Assistant NestJS API is designed to automate part of the code review process. When a Git event (such as a commit or pull request) is received, the API:

- Extracts code snippets (e.g., commit messages or diffs) from the webhook payload.
- Performs static analysis to generate quantitative quality metrics.
- Calls an external Python AI service that leverages OpenAI to provide qualitative feedback and actionable suggestions.
- Aggregates both the static scores and AI feedback into a comprehensive report.

---

## Features

- **Webhook Integration:**  
  Listens for GitHub/GitLab webhook events to trigger automated analysis.
  
- **Static Analysis:**  
  Analyzes code snippets using static analysis tools to assess aspects like formatting, structure, readability, and more.

- **AI-Powered Feedback:**  
  Forwards code snippets to a Python service that returns detailed, contextual improvement suggestions using OpenAI.

- **Unified Reporting:**  
  Aggregates static analysis scores and AI-generated feedback into a single, structured response.

---

## Technologies

- **NestJS:** For building a scalable and modular backend API.
- **Multer:** Middleware for handling file uploads (if needed for code files).
- **ESLint (or similar):** For static code analysis.
- **node-fetch:** For making HTTP requests to external services (Python AI service).
- **dotenv:** For managing environment variables.
- **TypeScript:** For strong typing and modern JavaScript features.

---

## Architecture

1. **Webhook Endpoint:**  
   A controller listens for Git webhook events, extracts code snippets from the payload, and triggers the analysis process.

2. **Static Analysis Module:**  
   A dedicated service performs static code analysis and returns quality metrics (e.g., scores for formatting, readability, etc.).

3. **AI Feedback Integration:**  
   The API forwards the extracted code snippet to a Python AI service (configured via an environment variable) which returns detailed improvement feedback.

4. **Aggregation & Reporting:**  
   Combines static analysis scores and AI feedback into a unified report that is sent back to the client or further processed.

---

## Setup and Installation

### Prerequisites

- Node.js (v16 or higher)
- npm or yarn
- Git

### Steps

1. **Clone the Repository:**

   ```bash
   git clone https://github.com/your-username/automated-code-review-api.git
   cd automated-code-review-api
   ```

2. **Install Dependencies:**

   ```bash
   pnpm install
   ```

3. **Configure Environment Variables:**

   Create a `.env` file in the root directory and add the following variables:

   ```
   PORT=3000
   PYTHON_API_URL=http://localhost:8000
   ```

4. **Run the Application Locally:**

   ```bash
   pnpm run start:dev
   ```

## Usage

### Webhook Endpoint

The API exposes a POST /webhook endpoint. This endpoint is designed to be used with GitHub/GitLab webhooks.

Example Request Payload (simplified):

```json
{
  "commits": [
    {
      "message": "Fixed bug in authentication flow"
    }
  ]
}
```

Response Example:

```json
{
  "message": "Webhook received",
  "analysis": {
    "staticScores": {
      "formatting": 80,
      "content_quality": 75,
      "structure": 70,
      "keyword_optimization": 65,
      "readability": 60,
      "achievements": 85,
      "professionalism": 90
    },
    "aiFeedback": "Detailed feedback generated by OpenAI..."
  }
}
```

### Testing

You can test the endpoint using Postman or by configuring a Git webhook with a tool like ngrok to expose your local server to the internet.

### Deployment

For free deployment, consider platforms such as Railway, Heroku, or Render. Make sure to:

Set your environment variables on the platform.

Use a Procfile if required (e.g., for Heroku):
```bash
web: npm run start:prod
```

Ensure that your application listens on the port provided by the deployment environment (using process.env.PORT).

## Future Improvements

- Enhanced File Parsing:
  Add support for parsing different types of code files or diffs beyond commit messages.
- Authentication:
  Secure the webhook endpoint to verify the source of the webhook.
- Detailed Reporting:
  Improve the aggregation logic to combine more in-depth static analysis metrics with AI feedback.
- Dashboard Integration:
  Optionally build a Next.js dashboard to display historical analysis reports.
- Notifications:
  Integrate with email or Slack APIs to send alerts when critical code quality issues are detected.
